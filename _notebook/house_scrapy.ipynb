{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 请求网页数据函数\n",
    "def get_html(url, header, proxies):        \n",
    "    rep = requests.get(url, headers= header, proxies= proxies, timeout=6)       \n",
    "    html = rep.text\n",
    "    html = re.sub('\\s', '', html) # 将html文本中非字符数据去掉        \n",
    "          \n",
    "    return html,proxies\n",
    "\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\",\n",
    "    \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)\",\n",
    "    \"Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\",\n",
    "    \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)\",\n",
    "    \"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)\",\n",
    "    \"Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)\",\n",
    "    \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)\",\n",
    "    \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1\",\n",
    "    \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20\",\n",
    "    \"Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52\",\n",
    "]\n",
    "\n",
    "def create_headers():\n",
    "    headers = dict()\n",
    "    headers[\"User-Agent\"] = random.choice(USER_AGENTS)\n",
    "    headers[\"Referer\"] = \"http://www.ke.com\"\n",
    "    return headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cq.fang.ke.com/loupan\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# 开始获得需要的板块数据\n",
    "total_page = 1\n",
    "loupan_list = list()\n",
    "base_site = 'https://cq.fang.ke.com/loupan'\n",
    "print(base_site)\n",
    "headers = create_headers()\n",
    "response = requests.get(base_site, timeout=10, headers=headers)\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "\n",
    "# 获得总的页数\n",
    "try:\n",
    "    page_box = soup.find_all('div', class_='page-box')[0]\n",
    "    matches = re.search('.*data-total-count=\"(\\d+)\".*', str(page_box))\n",
    "    total_page = int(math.ceil(int(matches.group(1)) / 10))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(total_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 从第一页开始,一直遍历到最后一页\n",
    "headers = create_headers()\n",
    "for i in range(1, total_page + 1):\n",
    "    page = 'http://zh.fang.ke.com/loupan/pg{0}'.format(i)\n",
    "    print(page)\n",
    "    response = requests.get(page, timeout=10, headers=headers)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "\n",
    "    # 获得有小区信息的panel\n",
    "    house_elements = soup.find_all('li', class_=\"resblock-list\")\n",
    "    for house_elem in house_elements:\n",
    "        price = house_elem.find('span', class_=\"number\")\n",
    "        desc = house_elem.find('span', class_=\"desc\")\n",
    "        total = house_elem.find('div', class_=\"second\")\n",
    "        loupan = house_elem.find('a', class_='name')\n",
    "\n",
    "\n",
    "        # 继续清理数据\n",
    "        try:\n",
    "            price = price.text.strip() + desc.text.strip()\n",
    "        except Exception as e:\n",
    "            price = '0'\n",
    "\n",
    "\n",
    "        loupan = loupan.text.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        try:\n",
    "            total = total.text.strip().replace(u'总价', '')\n",
    "            total = total.replace(u'/套起', '')\n",
    "        except Exception as e:\n",
    "            total = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for page in range(1,pages+1):\n",
    "    items = []\n",
    "    time.sleep(random.random())\n",
    "    info_url = f'{url}/pg{page}'\n",
    "    try:\n",
    "        info_html, proxies = get_html(info_url, proxies)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    sellListContent = re.findall(r'<ulclass=\"sellListContent\"log-mod=\"list\">(.*?)</ul>', info_html)[0]\n",
    "    Lists = re.findall(r'<liclass=\"clear\">(.*?)</li>', sellListContent)\n",
    "\n",
    "    for List in Lists:\n",
    "        try:\n",
    "            # 获取房屋信息\n",
    "            item = {}\n",
    "            item['标题'] = re.findall(r'detail\"title=\"(.*?)\"data-hreftype=', List)[0]\n",
    "            item['房子ID'] = re.findall(r'housedel_id=(\\d+)&', List)[0]\n",
    "            item['地址'] = re.findall(r'<ahref=\"(.*?)\">(.*)</a>', List)[0][1]\n",
    "            item['详情页'] = re.findall(r'<ahref=\"(.*?)\">(.*)</a>', List)[0][0]\n",
    "            item['详情'] = re.findall(r'<spanclass=\"houseIcon\"></span>(.*?)</div>', List)[0]\n",
    "            item['总价'] = re.findall(r'<divclass=\"totalPrice\"><span>(\\d+\\.?\\d*)</span>(.*?)</div>', List)[0][0]\n",
    "            item['总价单位'] = re.findall(r'<divclass=\"totalPrice\"><span>(\\d+\\.?\\d*)</span>(.*?)</div>', List)[0][1]\n",
    "            item['均价'] = re.findall(r'<divclass=\"unitPrice\".*<span>(.*?)</span></div></div></div>', List)[0]\n",
    "            item['关注人数'] = re.findall(r'<spanclass=\"starIcon\"></span>(.*?)</div>', List)[0]\n",
    "            item['地区'] = areaName\n",
    "            item['价格区间'] = priceRange\n",
    "            item['户型'] = layout\n",
    "            items.append(item)\n",
    "            num = num+1\n",
    "            print(f'{num}个房子信息已经采集!')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(item)\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
